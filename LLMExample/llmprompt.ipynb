{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Utilizing a prompt from GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "apiKey = os.getenv(\"API_KEY\")\n",
    "fragmentFiles = os.listdir(\"../Fragments/Training/Legacy\")\n",
    "\n",
    "client = OpenAI(api_key=apiKey)\n",
    "filetypes = {\"BMP\", \"BPG\", \"GIF\", \"JPEG\", \"JPF\", \"JXR\", \"PNG\", \"TIF\", \"WEBP\"}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "        You are a forensic investigator, based on the fragmented files from the datasets {fragmentFiles}, choose a random file and identify how you would determine its original file type based on these file types {filetypes}. \n",
    "        This analysis must include machine learning techniques, and you must provide a detailed explanation of the steps you would take to analyze the fragments and reconstruct the file type.\n",
    "    \"\"\"\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # or other GPT model\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "text = response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the original file type of a chosen fragmented file from the provided datasets, we can utilize a combination of data mining, feature extraction, and machine learning techniques. This systematic approach involves multiple stages, which I will outline below:\n",
      "\n",
      "### Step 1: Selecting a Random File\n",
      "I will randomly select a file from the provided list. For this explanation, let’s say we choose `Bqq865dlcs7.dat`.\n",
      "\n",
      "### Step 2: Fragment Analysis\n",
      "We will analyze the selected fragmented file (`Bqq865dlcs7.dat`) for any recognizable patterns or signatures associated with the file types specified (`JPEG`, `TIF`, `JPF`, `BPG`, `PNG`, `GIF`, `BMP`, `JXR`, `WEBP`). Here are the steps we would follow:\n",
      "\n",
      "1. **Read the Fragmented Data**: Load the contents of `Bqq865dlcs7.dat` into memory for analysis.\n",
      "\n",
      "2. **Extract Features**:\n",
      "    - **Magic Numbers**: Most file types have unique file signatures or \"magic numbers.\" For example:\n",
      "        - JPEG starts with `FF D8` (hexadecimal).\n",
      "        - PNG starts with `89 50 4E 47` (hexadecimal).\n",
      "        - GIF starts with `47 49 46` (hexadecimal).\n",
      "        - Others will have distinct sequences.\n",
      "    - Check for these known signatures in the data.\n",
      "\n",
      "3. **Entropy Analysis**: Different file types will exhibit varying levels of data entropy. For instance:\n",
      "    - Compressible formats like JPEG may show lower entropy than others like BMP or PNG.\n",
      "    - Calculate the Shannon entropy of the fragmented data. This can give us insights into its characteristics.\n",
      "\n",
      "4. **Byte Frequency Distribution**: The distribution of byte values can indicate what type of file it might represent. We can compute:\n",
      "    - The frequency of different byte values.\n",
      "    - Analyze patterns in byte sequences common in specific formats.\n",
      "\n",
      "### Step 3: Developing a Machine Learning Model\n",
      "Presently, we can use the features extracted from the previous analysis to train a machine learning model for classification:\n",
      "\n",
      "1. **Data Labeling**: First, we would need a labeled dataset consisting of examples from each file type. This dataset can include a variety of known examples of `JPEG`, `PNG`, `GIF`, etc., and their extracted features.\n",
      "\n",
      "2. **Feature Engineering**: Using the earlier extraction steps, we can assemble feature vectors. For instance, each vector might contain:\n",
      "    - A list of boolean variables indicating the presence of magic numbers.\n",
      "    - Entropy values.\n",
      "    - Byte frequency counts.\n",
      "\n",
      "3. **Model Selection**: We can choose various machine learning algorithms based on classification tasks, such as:\n",
      "    - Decision Trees\n",
      "    - Random Forests\n",
      "    - Support Vector Machines (SVM)\n",
      "    - Neural Networks\n",
      "    - k-Nearest Neighbors (k-NN)\n",
      "\n",
      "4. **Training**: Train the model on the labeled dataset using cross-validation to ensure it generalizes well to unseen data.\n",
      "\n",
      "5. **Testing and Validation**: Split the dataset into a training set and a testing set. Use the testing set to validate the model’s predictive accuracy in classifying file types.\n",
      "\n",
      "### Step 4: Classification and Reconstruction of the Original File Type\n",
      "Once the model is trained and validated, you can use it to classify fragments of `Bqq865dlcs7.dat`:\n",
      "\n",
      "1. **Extract Features from Fragment**: Utilize the feature extraction techniques on the fragmented file above.\n",
      "2. **Classify**: Input the feature vector into the trained machine learning model to predict the file type.\n",
      "3. **Reconstruction**: If the file type can be confidently identified, reconstruct the original file format based on the predictions.\n",
      "\n",
      "### Conclusion\n",
      "Although this process may present challenges such as noise in the data and the presence of incomplete fragments, by systematically extracting features and leveraging machine learning techniques, we can effectively classify the fragmented files and determine their original types. This multi-step process allows for a thorough investigation capable of handling a variety of file types and data inconsistencies.\n"
     ]
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
